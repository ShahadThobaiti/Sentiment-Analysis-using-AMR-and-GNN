{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Iterable\n",
    "from pydot import Dot, graph_from_dot_data, Edge\n",
    "from graphviz.graphs import BaseGraph\n",
    "from graphviz import Source\n",
    "import amrlib\n",
    "from amrlib.graph_processing.amr_plot import AMRPlot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv, pickle\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract nodes and edges from AMR graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_dot_obj(graph_spec) -> List[Dot]:\n",
    "    \"\"\"Get a dot (graphs) object list from a variety \n",
    "    of possible sources (postelizing inputs here)\"\"\"\n",
    "    _original_graph_spec = graph_spec\n",
    "    if isinstance(graph_spec, (BaseGraph, Source)):\n",
    "        # get the source (str) from a graph object\n",
    "        graph_spec = graph_spec.source\n",
    "    if isinstance(graph_spec, str):\n",
    "        # get a dot-graph from dot string data\n",
    "        graph_spec = graph_from_dot_data(graph_spec)\n",
    "    # make sure we have a list of Dot objects now\n",
    "    assert isinstance(graph_spec, list) and all(\n",
    "        isinstance(x, Dot) for x in graph_spec\n",
    "    ), (\n",
    "        f\"Couldn't get a proper dot object list from: {_original_graph_spec}. \"\n",
    "        f\"At this point, we should have a list of Dot objects, but was: {graph_spec}\"\n",
    "    )\n",
    "    return graph_spec\n",
    "\n",
    "def get_edges(graph_spec, label = False):\n",
    "    \"\"\"Get a list of edges for a given graph (or list of lists thereof).\n",
    "    If ``postprocess_edges`` is ``None`` the function will return ``pydot.Edge`` objects from\n",
    "    which you can extract any information you want.\n",
    "    By default though, it is set to extract the node pairs for the edges, and you can\n",
    "    replace with any function that takes ``pydot.Edge`` as an input.\n",
    "    \"\"\"\n",
    "    graphs = get_graph_dot_obj(graph_spec)\n",
    "    n_graphs = len(graphs)\n",
    "    if n_graphs > 1:\n",
    "        return [get_edges(graph) for graph in graphs]\n",
    "    elif n_graphs == 0:\n",
    "        raise ValueError(f\"Your input had no graphs\")\n",
    "    else:\n",
    "        graph = graphs[0]\n",
    "        edges = graph.get_edges()\n",
    "        edges_list = []\n",
    "        if not label:\n",
    "            for edge in edges:\n",
    "                r1, r2 = graph.get_node(edge.get_source())[0].get_label().strip('\\\"').strip('\\\\').strip('\\\"'), graph.get_node(edge.get_destination())[0].get_label().strip('\\\"').strip('\\\\').strip('\\\"')\n",
    "                if '/' in r1:\n",
    "                    r1 = r1.split('/')[1]\n",
    "                elif '\\\\' in r1:\n",
    "                    r1 = r1.split('\\\\')[0]\n",
    "                \n",
    "                if '/' in r2:\n",
    "                    r2 = r2.split('/')[1]\n",
    "                elif '\\\\' in r1:\n",
    "                    r2 = r2.split('\\\\')[0]\n",
    "\n",
    "                edges_list.append([r1,r2])\n",
    "        else:\n",
    "            for edge in edges:\n",
    "                r1, r2, r3 = graph.get_node(edge.get_source())[0].get_label().strip('\\\"').strip('\\\\').strip('\\\"'), graph.get_node(edge.get_destination())[0].get_label().strip('\\\"').strip('\\\\').strip('\\\"'), edge.get_label().strip('\\\"')[1:]\n",
    "                if '/' in r1:\n",
    "                    r1 = r1.split('/')[1]\n",
    "                elif '\\\\' in r1:\n",
    "                    r1 = r1.split('\\\\')[0]\n",
    "                \n",
    "                if '/' in r2:\n",
    "                    r2 = r2.split('/')[1]\n",
    "                elif '\\\\' in r1:\n",
    "                    print(\"called\")\n",
    "                    r2 = r2.split('\\\\')[0]\n",
    "\n",
    "                edges_list.append([r1,r2,r3])\n",
    "        \n",
    "        return edges_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save large intermediate results (Only used for the first run). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_AMR.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    next(csv_reader, None)\n",
    "    g_train = []\n",
    "    for row in tqdm(csv_reader, total=1600):\n",
    "        AP = AMRPlot()\n",
    "        AP.build_from_graph(entry = row)\n",
    "        edges = get_edges(AP.graph, label=True)\n",
    "        g_train.append(edges)\n",
    "\n",
    "    np.save('g_train',g_train)\n",
    "\n",
    "with open('test_AMR.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    next(csv_reader, None)\n",
    "    g_test = []\n",
    "    for row in tqdm(csv_reader, total=400):\n",
    "        AP = AMRPlot()\n",
    "        AP.build_from_graph(entry = row)\n",
    "        edges = get_edges(AP.graph, label=True)\n",
    "        g_test.append(edges)\n",
    "\n",
    "    np.save('g_test',g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600,) (400,) (2000,) <class 'numpy.ndarray'>\n",
      "[['find-01', 'i', 'ARG0'], ['find-01', 'this', 'ARG1'], ['find-01', 'company', 'location'], ['company', 'name', 'name'], ['name', 'Target', 'op1']]\n"
     ]
    }
   ],
   "source": [
    "gtrs = np.load('g_train.npy',allow_pickle=True) # list of edges for each \n",
    "gtes = np.load('g_test.npy',allow_pickle=True)\n",
    "gall = np.concatenate((gtrs, gtes), axis=0)\n",
    "print(gtrs.shape, gtes.shape, gall.shape, type(gtrs))\n",
    "print(gtrs[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate inventories for words and edge labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5138, 109)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set = list({ts[i] for g in gall for ts in g for i in range(2)})\n",
    "edge_set = list({ts[2] for g in gall for ts in g})\n",
    "word_set.sort()\n",
    "edge_set.sort()\n",
    "word_to_id = dict(zip(word_set,[i for i in range(len(word_set))]))\n",
    "edge_to_id = dict(zip(edge_set,[i for i in range(len(edge_set))]))\n",
    "Vsize, Esize = len(word_to_id), len(edge_to_id)\n",
    "Vsize, Esize # number of node features and number of edge lables in our corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Embedding. Get x, edge_index, edge_attr for each graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_embedding(edges):\n",
    "    # for a single tweet amr    \n",
    "    # print(edges,\"\\n\")\n",
    "    nodes = list({edge[i] for edge in edges for i in range(2)})\n",
    "    nodes_to_id = dict(zip(nodes,[i for i in range(len(nodes))]))\n",
    "    edge_index = [[nodes_to_id[edge[0]] for edge in edges], [nodes_to_id[edge[1]] for edge in edges]]\n",
    "    x, edge_attr = [], []\n",
    "    for node in nodes_to_id.keys():\n",
    "        vector = np.zeros(Vsize)\n",
    "        vector[word_to_id[node]] = 1.0 # one-hot vector\n",
    "        x.append(vector)\n",
    "\n",
    "    for edge in edges:\n",
    "        vector = np.zeros(Esize)\n",
    "        vector[edge_to_id[edge[2]]] = 1.0 # one-hot vector\n",
    "        edge_attr.append(vector)\n",
    "\n",
    "    return np.array(x), np.array(edge_index), np.array(edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get AMR classes (labels) and represent them as numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 400\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def label_converter(labels):\n",
    "    nlabels = []\n",
    "    for label in labels:\n",
    "        if label == 'Positive':\n",
    "            nlabels.append(2)\n",
    "        elif label == 'Negative':\n",
    "            nlabels.append(0)\n",
    "        else:\n",
    "            nlabels.append(1)\n",
    "    return nlabels\n",
    "\n",
    "with open('train_label.csv', 'r') as train_label, open('test_label.csv', 'r') as test_label:\n",
    "    y_train = train_label.read().split('\\n')\n",
    "    y_test = test_label.read().split('\\n')\n",
    "    y_train = label_converter(y_train)\n",
    "    y_test = label_converter(y_test)\n",
    "\n",
    "print(len(y_train), len(y_test))\n",
    "print(y_train[4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate datasets for GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 400\n",
      "Data(x=[6, 5138], edge_index=[2, 5], edge_attr=[5, 109], y=[1]) Data(x=[24, 5138], edge_index=[2, 23], edge_attr=[23, 109], y=[1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def get_dataset(graph,labels):\n",
    "    dataset = []\n",
    "    for i in range(len(graph)):\n",
    "        x, edge_index, edge_attr = data_embedding(graph[i])\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "        dataset.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=[labels[i]]))\n",
    "    return dataset\n",
    "\n",
    "train_dataset = get_dataset(gtrs,y_train)\n",
    "test_dataset = get_dataset(gtes, y_test)\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "print(train_dataset[4], test_dataset[48])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30986652c4ab4ff281045d6c95a45743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.084760043194934\n",
      "1.073526939774537\n",
      "1.0627700732466046\n",
      "1.0509009588364222\n",
      "1.044659347353953\n",
      "1.0375549915049185\n",
      "1.0329572935323161\n",
      "1.0277744091565146\n",
      "1.024126139838752\n",
      "1.020378950613382\n",
      "1.0175401900658083\n",
      "1.015193633360503\n",
      "1.0148525621615527\n",
      "1.0121207810690165\n",
      "1.011747961872228\n",
      "1.0112865842940868\n",
      "1.0099386606343963\n",
      "1.0096647200973503\n",
      "1.0084022329278972\n",
      "1.0084946438703568\n",
      "1.0066054695423676\n",
      "1.0071355778387463\n",
      "1.00691866067827\n",
      "1.00611443262521\n",
      "1.005459534606916\n",
      "1.005785628549473\n",
      "1.0056076830779224\n",
      "1.0048592304482742\n",
      "1.0057802177073099\n",
      "1.0043717892070867\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GCN2Conv, Linear\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(Vsize, 16)\n",
    "        self.conv2 = GCNConv(16, 3)\n",
    "        # self.lin1 = torch.nn.Linear(256, 128)\n",
    "        # self.lin2 = torch.nn.Linear(128, 64)\n",
    "        # self.lin3 = torch.nn.Linear(64, 3)\n",
    "        # self.act1 = torch.nn.ReLU()\n",
    "        # self.act2 = torch.nn.ReLU() \n",
    "  \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        # x = self.lin1(x)\n",
    "        # x = self.act1(x)\n",
    "        # x = self.lin2(x)\n",
    "        # x = self.act2(x) \n",
    "        # x = self.lin3(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "model.train()\n",
    "for epoch in tqdm(range(30), total=30):\n",
    "    avg_loss = []\n",
    "    for i in range(1600):\n",
    "        if not gtrs[i]: # ignore empty graph\n",
    "            continue\n",
    "        data = train_dataset[i]\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, torch.tensor(data.y*np.ones(out.shape[0]), dtype=torch.long))\n",
    "        loss.backward()\n",
    "        avg_loss.append(loss.item())\n",
    "        optimizer.step()\n",
    "    print(np.average(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Precision: 0.4076103099495805\n",
      "Graph Precision: 0.39896373056994816\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "model.eval()\n",
    "precision = []\n",
    "accuracy = []\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for i in range(400):\n",
    "    if not gtes[i]: \n",
    "        continue # ignore empty graph\n",
    "    pred = model(test_dataset[i]).argmax(dim=1)\n",
    "    correct_node = (pred.numpy() == test_dataset[i].y*np.ones(pred.shape[0])).astype(np.float32).sum()\n",
    "    precision.append(correct_node/pred.shape[0])\n",
    "    accuracy.append(1 if correct_node >= 0.5*pred.shape[0] else 0) # Majority Voting\n",
    "    y_true.append(test_dataset[i].y[0])\n",
    "    # print(pred,test_dataset[i].y[0] )\n",
    "    if correct_node >= 0.5*pred.shape[0]:\n",
    "        y_pred.append(test_dataset[i].y[0])\n",
    "    else:\n",
    "        y_pred.append(Counter(pred.numpy()).most_common(1)[0][0])\n",
    "    \n",
    "\n",
    "print(\"Node Precision:\", np.average(precision))\n",
    "print(\"Graph Precision:\",np.array(accuracy).sum()/np.array(accuracy).shape[0])\n",
    "# print(y_true, y_pred)\n",
    "\n",
    "# precision = []\n",
    "# accuracy = []\n",
    "# for i in range(1600):\n",
    "#     if not gtrs[i]: \n",
    "#         continue # ignore empty graph\n",
    "#     pred = model(train_dataset[i]).argmax(dim=1)\n",
    "#     correct_node = (pred.numpy() == train_dataset[i].y*np.ones(pred.shape[0])).astype(np.float32).sum()\n",
    "#     # print(correct_node,pred.shape[0],test_dataset[i].y)\n",
    "#     precision.append(correct_node/pred.shape[0])\n",
    "#     accuracy.append(1 if correct_node >= 0.5*pred.shape[0] else 0) # Majority Voting\n",
    "\n",
    "# print(\"Node Precision:\", np.average(precision))\n",
    "# print(\"Graph Precision:\",np.array(accuracy).sum()/np.array(accuracy).shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(accuracy))\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "classes = (\"0\",\"1\",\"2\")\n",
    "    \n",
    "cf_matrix = confusion_matrix(y_pred, y_true)\n",
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('output.png')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e76047571534d9678569ee9117847be362aff1ac80d7491f5f35fa09585552a9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
