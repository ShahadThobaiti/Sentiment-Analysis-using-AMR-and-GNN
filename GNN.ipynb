{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Iterable\n",
    "from pydot import Dot, graph_from_dot_data, Edge\n",
    "from graphviz.graphs import BaseGraph\n",
    "from graphviz import Source\n",
    "import amrlib\n",
    "from amrlib.graph_processing.amr_plot import AMRPlot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv, pickle\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract nodes and edges from AMR graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_dot_obj(graph_spec) -> List[Dot]:\n",
    "    \"\"\"Get a dot (graphs) object list from a variety \n",
    "    of possible sources (postelizing inputs here)\"\"\"\n",
    "    _original_graph_spec = graph_spec\n",
    "    if isinstance(graph_spec, (BaseGraph, Source)):\n",
    "        # get the source (str) from a graph object\n",
    "        graph_spec = graph_spec.source\n",
    "    if isinstance(graph_spec, str):\n",
    "        # get a dot-graph from dot string data\n",
    "        graph_spec = graph_from_dot_data(graph_spec)\n",
    "    # make sure we have a list of Dot objects now\n",
    "    assert isinstance(graph_spec, list) and all(\n",
    "        isinstance(x, Dot) for x in graph_spec\n",
    "    ), (\n",
    "        f\"Couldn't get a proper dot object list from: {_original_graph_spec}. \"\n",
    "        f\"At this point, we should have a list of Dot objects, but was: {graph_spec}\"\n",
    "    )\n",
    "    return graph_spec\n",
    "\n",
    "def get_edges(graph_spec, label = False):\n",
    "    \"\"\"Get a list of edges for a given graph (or list of lists thereof).\n",
    "    If ``postprocess_edges`` is ``None`` the function will return ``pydot.Edge`` objects from\n",
    "    which you can extract any information you want.\n",
    "    By default though, it is set to extract the node pairs for the edges, and you can\n",
    "    replace with any function that takes ``pydot.Edge`` as an input.\n",
    "    \"\"\"\n",
    "    graphs = get_graph_dot_obj(graph_spec)\n",
    "    n_graphs = len(graphs)\n",
    "    if n_graphs > 1:\n",
    "        return [get_edges(graph) for graph in graphs]\n",
    "    elif n_graphs == 0:\n",
    "        raise ValueError(f\"Your input had no graphs\")\n",
    "    else:\n",
    "        graph = graphs[0]\n",
    "        edges = graph.get_edges()\n",
    "        edges_list = []\n",
    "        if not label:\n",
    "            for edge in edges:\n",
    "                r1, r2 = graph.get_node(edge.get_source())[0].get_label().strip('\\\"').strip('\\\\').strip('\\\"'), graph.get_node(edge.get_destination())[0].get_label().strip('\\\"').strip('\\\\').strip('\\\"')\n",
    "                if '/' in r1:\n",
    "                    r1 = r1.split('/')[1]\n",
    "                elif '\\\\' in r1:\n",
    "                    r1 = r1.split('\\\\')[0]\n",
    "                \n",
    "                if '/' in r2:\n",
    "                    r2 = r2.split('/')[1]\n",
    "                elif '\\\\' in r1:\n",
    "                    r2 = r2.split('\\\\')[0]\n",
    "\n",
    "                edges_list.append([r1,r2])\n",
    "        else:\n",
    "            for edge in edges:\n",
    "                r1, r2, r3 = graph.get_node(edge.get_source())[0].get_label().strip('\\\"').strip('\\\\').strip('\\\"'), graph.get_node(edge.get_destination())[0].get_label().strip('\\\"').strip('\\\\').strip('\\\"'), edge.get_label().strip('\\\"')[1:]\n",
    "                if '/' in r1:\n",
    "                    r1 = r1.split('/')[1]\n",
    "                elif '\\\\' in r1:\n",
    "                    r1 = r1.split('\\\\')[0]\n",
    "                \n",
    "                if '/' in r2:\n",
    "                    r2 = r2.split('/')[1]\n",
    "                elif '\\\\' in r1:\n",
    "                    print(\"called\")\n",
    "                    r2 = r2.split('\\\\')[0]\n",
    "\n",
    "                edges_list.append([r1,r2,r3])\n",
    "        \n",
    "        return edges_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save large intermediate results (Only used for the first run). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_AMR.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    next(csv_reader, None)\n",
    "    g_train = []\n",
    "    for row in tqdm(csv_reader, total=1600):\n",
    "        AP = AMRPlot()\n",
    "        AP.build_from_graph(entry = row)\n",
    "        edges = get_edges(AP.graph, label=True)\n",
    "        g_train.append(edges)\n",
    "\n",
    "    np.save('g_train',g_train)\n",
    "\n",
    "with open('test_AMR.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    next(csv_reader, None)\n",
    "    g_test = []\n",
    "    for row in tqdm(csv_reader, total=400):\n",
    "        AP = AMRPlot()\n",
    "        AP.build_from_graph(entry = row)\n",
    "        edges = get_edges(AP.graph, label=True)\n",
    "        g_test.append(edges)\n",
    "\n",
    "    np.save('g_test',g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600,) (400,) (2000,) <class 'numpy.ndarray'>\n",
      "[['find-01', 'i', 'ARG0'], ['find-01', 'this', 'ARG1'], ['find-01', 'company', 'location'], ['company', 'name', 'name'], ['name', 'Target', 'op1']]\n"
     ]
    }
   ],
   "source": [
    "gtrs = np.load('g_train.npy',allow_pickle=True) # list of edges for each \n",
    "gtes = np.load('g_test.npy',allow_pickle=True)\n",
    "gall = np.concatenate((gtrs, gtes), axis=0)\n",
    "print(gtrs.shape, gtes.shape, gall.shape, type(gtrs))\n",
    "print(gtrs[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate inventories for words and edge labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5138, 109)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set = list({ts[i] for g in gall for ts in g for i in range(2)})\n",
    "edge_set = list({ts[2] for g in gall for ts in g})\n",
    "word_set.sort()\n",
    "edge_set.sort()\n",
    "word_to_id = dict(zip(word_set,[i for i in range(len(word_set))]))\n",
    "edge_to_id = dict(zip(edge_set,[i for i in range(len(edge_set))]))\n",
    "Vsize, Esize = len(word_to_id), len(edge_to_id)\n",
    "Vsize, Esize # number of node features and number of edge lables in our corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Embedding. Get x, edge_index, edge_attr for each graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_embedding(edges):\n",
    "    # for a single tweet amr    \n",
    "    # print(edges,\"\\n\")\n",
    "    nodes = list({edge[i] for edge in edges for i in range(2)})\n",
    "    nodes_to_id = dict(zip(nodes,[i for i in range(len(nodes))]))\n",
    "    edge_index = [[nodes_to_id[edge[0]] for edge in edges], [nodes_to_id[edge[1]] for edge in edges]]\n",
    "    x, edge_attr = [], []\n",
    "    for node in nodes_to_id.keys():\n",
    "        vector = np.zeros(Vsize)\n",
    "        vector[word_to_id[node]] = 1.0 # one-hot vector\n",
    "        x.append(vector)\n",
    "\n",
    "    for edge in edges:\n",
    "        vector = np.zeros(Esize)\n",
    "        vector[edge_to_id[edge[2]]] = 1.0 # one-hot vector\n",
    "        edge_attr.append(vector)\n",
    "\n",
    "    return np.array(x), np.array(edge_index), np.array(edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get AMR classes (labels) and represent them as numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 400\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def label_converter(labels):\n",
    "    nlabels = []\n",
    "    for label in labels:\n",
    "        if label == 'Positive':\n",
    "            nlabels.append(2)\n",
    "        elif label == 'Negative':\n",
    "            nlabels.append(0)\n",
    "        else:\n",
    "            nlabels.append(1)\n",
    "    return nlabels\n",
    "\n",
    "with open('train_label.csv', 'r') as train_label, open('test_label.csv', 'r') as test_label:\n",
    "    y_train = train_label.read().split('\\n')\n",
    "    y_test = test_label.read().split('\\n')\n",
    "    y_train = label_converter(y_train)\n",
    "    y_test = label_converter(y_test)\n",
    "\n",
    "print(len(y_train), len(y_test))\n",
    "print(y_train[4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate datasets for GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 400\n",
      "Data(x=[6, 5138], edge_index=[2, 5], edge_attr=[5, 109], y=[1]) Data(x=[24, 5138], edge_index=[2, 23], edge_attr=[23, 109], y=[1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def get_dataset(graph,labels):\n",
    "    dataset = []\n",
    "    for i in range(len(graph)):\n",
    "        x, edge_index, edge_attr = data_embedding(graph[i])\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "        dataset.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=[labels[i]]))\n",
    "    return dataset\n",
    "\n",
    "train_dataset = get_dataset(gtrs,y_train)\n",
    "test_dataset = get_dataset(gtes, y_test)\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "print(train_dataset[4], test_dataset[48])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d23df98105645f488c069e4a6489393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.08487006916899\n",
      "1.0715487500095429\n",
      "1.0567564603697788\n",
      "1.0469714581088176\n",
      "1.0371898194556624\n",
      "1.0319762370268135\n",
      "1.028529147661072\n",
      "1.0255984300992127\n",
      "1.0219435047079057\n",
      "1.0191304033334576\n",
      "1.0181216245313092\n",
      "1.017830712759532\n",
      "1.0164766482075749\n",
      "1.0163530586937695\n",
      "1.0157254490808063\n",
      "1.0157391641314053\n",
      "1.0137123727256971\n",
      "1.0149653876685967\n",
      "1.0129549282034387\n",
      "1.0142309378968608\n",
      "1.0138676379670668\n",
      "1.013095054027316\n",
      "1.0141770448362661\n",
      "1.0125497824928267\n",
      "1.0115725753541314\n",
      "1.0129139959301459\n",
      "1.011341536109748\n",
      "1.0116212122872577\n",
      "1.0125730313255685\n",
      "1.0109741956420353\n",
      "1.0104624623549694\n",
      "1.0103206236158844\n",
      "1.011335256680116\n",
      "1.0110468748786285\n",
      "1.0104965275680928\n",
      "1.0113915426926277\n",
      "1.010121845897385\n",
      "1.010620957851997\n",
      "1.009609945697148\n",
      "1.0102902897594832\n",
      "1.0092145432530164\n",
      "1.0103384232748727\n",
      "1.0100407559594078\n",
      "1.0100800210048018\n",
      "1.0109130533765298\n",
      "1.0118568167830224\n",
      "1.0091545422699286\n",
      "1.0108323138729836\n",
      "1.01001827182185\n",
      "1.0110687835900916\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(Vsize, 8)\n",
    "        self.conv2 = GCNConv(8, 3)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)    \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "model.train()\n",
    "for epoch in tqdm(range(50), total=50):\n",
    "    avg_loss = []\n",
    "    for i in range(1600):\n",
    "        if not gtrs[i]: # ignore empty graph\n",
    "            continue\n",
    "        data = train_dataset[i]\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, torch.tensor(data.y*np.ones(out.shape[0]), dtype=torch.long))\n",
    "        loss.backward()\n",
    "        avg_loss.append(loss.item())\n",
    "        optimizer.step()\n",
    "    print(np.average(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Node Precision: 0.40427116209747016\n",
      "Testing Graph Precision: 0.4173357512953368\n",
      "Training Node Precision: 0.5138989596069024\n",
      "Training Graph Precision: 0.5144138372837924\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "model.eval()\n",
    "precision = []\n",
    "accuracy = []\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for i in range(400):\n",
    "    if not gtes[i]: \n",
    "        continue # ignore empty graph\n",
    "    pred = model(test_dataset[i]).argmax(dim=1)\n",
    "    correct_node = (pred.numpy() == test_dataset[i].y*np.ones(pred.shape[0])).astype(np.float32).sum()\n",
    "    precision.append(correct_node/pred.shape[0])\n",
    "    accuracy.append(1 if correct_node >= 0.5*pred.shape[0] else 0) # Majority Voting\n",
    "    y_true.append(test_dataset[i].y[0])\n",
    "    if correct_node >= 0.5*pred.shape[0]:\n",
    "        y_pred.append(test_dataset[i].y[0])\n",
    "    else:\n",
    "        y_pred.append(Counter(pred.numpy()).most_common(1)[0][0])\n",
    "    \n",
    "\n",
    "print(\"Testing Node Precision:\", np.average(precision))\n",
    "print(\"Testing Graph Precision:\",np.array(accuracy).sum()/np.array(accuracy).shape[0])\n",
    "\n",
    "precision = []\n",
    "accuracy = []\n",
    "for i in range(1600):\n",
    "    if not gtrs[i]: \n",
    "        continue # ignore empty graph\n",
    "    pred = model(train_dataset[i]).argmax(dim=1)\n",
    "    correct_node = (pred.numpy() == train_dataset[i].y*np.ones(pred.shape[0])).astype(np.float32).sum()\n",
    "    precision.append(correct_node/pred.shape[0])\n",
    "    accuracy.append(1 if correct_node >= 0.5*pred.shape[0] else 0) # Majority Voting\n",
    "\n",
    "print(\"Training Node Precision:\", np.average(precision))\n",
    "print(\"Training Graph Precision:\",np.array(accuracy).sum()/np.array(accuracy).shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "classes = (\"Negative\",\"Neutral\",\"Positive\")\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "class_labels = ['Positive', 'Negative', 'Neutral']\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = classes)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('GNN')\n",
    "plt.savefig(\"gnncm.png\", dpi = 500)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e76047571534d9678569ee9117847be362aff1ac80d7491f5f35fa09585552a9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
